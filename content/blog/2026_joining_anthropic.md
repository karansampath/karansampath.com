---
title: "2026: Joining Anthropic and the Rise of Artists"
date: 2026-01-21
author: "Karan Sampath"
---

2026 is going to be an odd year. I anticipate there being a sea change in the broad perception of AI, shifting from a unique piece of technology that one can play with to a real factor in global labor productivity. Humans will likely be forced to move between layers of abstraction at an unprecedented speed, which would raise internal quandaries around their own meaning and purpose. Through it all, there will be a discussion at every level from the personal to the global on what it means to be human, and what it means to be artificial. Our intelligence will be our companion in this transition.

## The Year Ahead

I want to think about what the end of 2026 could look like, and what we can do about it. I’m intentionally choosing not to predict further out, since any prediction is likely to compound the already widely spread error bars here, and I’m going to be looking at what I believe to be the median case of AI growth. 

I believe 2026 will be the year a sizable (>10%) proportion of the digital white collar labor market in the US begins to get commoditized. By commoditization I mean the value offered by the human will be near replaceable. I arrive at this number by noting the advances in coding and the fact that 7-10% of white collar workers are in tech, with AI expanding to other roles now. To be clear, I believe the models of today are already nearly capable of this, it is a matter of figuring out the correct product surfaces and speeding up diffusion through the economy. From a consumer standpoint, I believe we will have a sizable (>2%) of US adult population having more words exchanged with AI models than with all humans combined that year. This is admittedly more of a guess and harder to verify, but I believe is the correct extrapolation of the trend. Notably, in both cases, it will begin to feel real and directly impactful to the wider population, and the AI bubble talk will die down. Of course, these may not come true at all, in which case the AI bubble would have likely burst and the world can take another breath.

In the case that these scenarios do take place, however, I posit that there will be a reckoning for humanity, one that pushes us towards an artisanal pursuit of life. I mean artisanal here as the prioritisation of human creative skill and imagination in a pursuit that may or may not have economic benefit. A necessary extension of this will be the development of a sense of taste and voice for each of us. LLMs will always struggle at this, since by design they are meant to encompass the whole range of tastes that can exist. Human authenticity could be as little as picking or defining a ‘taste’ for the model to develop on, and as much as not using AI models at all. I anticipate the latter being a rare case, with a gradual decrescendo in AI usage that skews over time. The fact here is there simply has never been as much of a need for this as now. Creativity and a sense of artistry must surely but slowly be a part of everyone’s life, and the artisanal coder and investment banker will slowly become more commonplace.

The pessimist here may say that this is likely to be taken over by AI models anyways, which is certainly possible. However, as seen in the [growing need for Japanese artisanal matcha](https://www.ft.com/content/be14c1f5-c6d4-4583-bf5b-c64d4d76a679), overproduction of a machine good often leads to a reversion to a want for artisanal human made options. Of course, this is at a premium, and there will need to be discussions on wealth redistribution in an AI based future, but the benefit to human purpose accrues regardless.

## Joining Anthropic

In a world of artists, it’s vital that we demand the same from our AIs too. Anthropic is, in my mind, the artisanal company. It has a specific view of the AI future, and takes limited focused bets to achieve it.

I believe having a sense of taste is downstream of a deep sense of care, something that is emphasized in almost every part of Anthropic's work. The day I write this, the company released [Claude's constitution](https://www.anthropic.com/news/claude-new-constitution), a foundational document that outlines so much of why I believe this moment is different and Anthropic is unique. I'd encourage you to read it if you haven't yet.

Anthropic’s vision is building an AI future that supports human cognition, rather than impedes it. This looks like products that encourage thought in a healthy manner without optimizing for engagement, a warm aesthetic that creates a safe space, and models that feel like they’ve been grown rather than built. The last part is worth expanding on, because model personality can be upstream of a lot of the behaviors and capabilities, and a model that feels comfortable in its own skin is often able to not only deliver novel outcomes but also has a positive effect on the human or model it interacts with. After joining, I’ve been startled and impressed at the high level of transparency, trust, and ownership within the organization, particularly from leadership, which is rare for a company of this scale. 

There are several risks, and criticisms, that will come, but that only serves to make the work and mission more meaningful. I’m excited for the journey here.
